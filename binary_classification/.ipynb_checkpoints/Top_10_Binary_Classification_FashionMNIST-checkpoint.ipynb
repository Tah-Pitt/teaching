{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Algorithms for Binary Classification [Beginner's Guide]\n",
    "\n",
    "#### How to implement the 10 most important binary classification algorithms with a few lines of Python and how they perform\n",
    "\n",
    "\n",
    "1. Naive Bayes\n",
    "2. Logistic Regression\n",
    "3. K-Nearest Neighbours\n",
    "4. Support Vector Machine\n",
    "5. Decision Tree \n",
    "6. Bagging  Decision Tree (Ensemble Learning I)\n",
    "7. Boosted Decision Tree (Ensemble Learning II)\n",
    "8. Random Forest (Ensemble Learning III)\n",
    "9. Voting Classification (Ensemble Learning IV)\n",
    "10. Deep Learning with a neuronal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.datasets as keras_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "https://keras.io/api/datasets/fashion_mnist/\n",
    "\n",
    "We turn a multilabel classification into a binary classification question for image vision by answering the important and valid questions **shoe or not shoe**\n",
    "Not shoe will be converted into 0 and shoe (Sandal, Sneaker, Ankle Boot) into 1\n",
    "\n",
    "|Label | Description | Binary Label |\n",
    "|--|--|--|\n",
    "|0|\tT-shirt/top|0|\n",
    "|1|\tTrouser|0|\n",
    "|2|\tPullover|0|\n",
    "|3|\tDress|0|\n",
    "|4|\tCoat|0|\n",
    "|5|\tSandal|1|\n",
    "|6|\tShirt|0|\n",
    "|7|\tSneaker|1|\n",
    "|8|\tBag|0|\n",
    "|9|\tAnkle boot|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Load data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from keras.dataset and directly split the tuples into seperated variables\n",
    "\n",
    "(fashion_train_data,fashion_train_labels),(fashion_test_data,fashion_test_labels)=keras_data.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Check out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fashion_train_data.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(fashion_train_data[6],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Vectorize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=fashion_train_data.reshape((60000,28*28))\n",
    "x_test=fashion_test_data.reshape((10000,28*28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train=fashion_train_labels.copy()\n",
    "y_train[y_train==0]=0\n",
    "y_train[y_train==1]=0\n",
    "y_train[y_train==2]=0\n",
    "y_train[y_train==3]=0\n",
    "y_train[y_train==4]=0\n",
    "y_train[y_train==5]=1\n",
    "y_train[y_train==6]=0\n",
    "y_train[y_train==7]=1\n",
    "y_train[y_train==8]=0\n",
    "y_train[y_train==9]=1\n",
    "\n",
    "y_test=fashion_test_labels.copy()\n",
    "y_test[y_test==0]=0\n",
    "y_test[y_test==1]=0\n",
    "y_test[y_test==2]=0\n",
    "y_test[y_test==3]=0\n",
    "y_test[y_test==4]=0\n",
    "y_test[y_test==5]=1\n",
    "y_test[y_test==6]=0\n",
    "y_test[y_test==7]=1\n",
    "y_test[y_test==8]=0\n",
    "y_test[y_test==9]=1\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n",
    "Sklearn Documentation: \n",
    "* Naive Bayes: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "* MultinomialNB: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9851\n",
      "score on train: 0.9833666666666666\n",
      "CPU times: user 2.51 s, sys: 299 ms, total: 2.81 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(mnb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression\n",
    "\n",
    "Sklearn Documentation: \n",
    "* LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* SGD Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.995\n",
      "score on train: 1.0\n",
      "CPU times: user 2min 34s, sys: 1.23 s, total: 2min 35s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(lr.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9968\n",
      "score on train: 0.99905\n",
      "CPU times: user 6.69 s, sys: 225 ms, total: 6.92 s\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logistic regression with stochastic gradient decent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(sgd.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(sgd.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-Nearest Neighbours\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9981\n",
      "score on train: 0.9987\n",
      "CPU times: user 10min 37s, sys: 1min 5s, total: 11min 42s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5,algorithm = 'ball_tree')\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine\n",
    "\n",
    "Sklearn Documentation:\n",
    "* SVM Overview: https://scikit-learn.org/stable/modules/svm.html\n",
    "* LinearSVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9955\n",
      "score on train: 0.9999166666666667\n",
      "CPU times: user 6.95 s, sys: 338 ms, total: 7.29 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm=LinearSVC(C=0.0001,max_iter=10000)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(svm.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(svm.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9961\n",
      "score on train: 1.0\n",
      "CPU times: user 42.8 s, sys: 275 ms, total: 43.1 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \"  + str(clf.score(x_test, y_test)))\n",
    "print(\"score on train: \" + str(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bagging Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* overview ensemble methods: https://scikit-learn.org/stable/modules/ensemble.html\n",
    "* bagging classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.997\n",
      "score on train: 0.9985166666666667\n",
      "CPU times: user 1min 46s, sys: 1.52 s, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(bg.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Boosting Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* AdaBoost Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "* Gradien Boosting Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9982\n",
      "score on train: 0.9999\n",
      "CPU times: user 1min 39s, sys: 2.08 s, total: 1min 41s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "adb.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(adb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 784)\n",
      "score on test: 0.9931\n",
      "score on train: 0.9922333333333333\n",
      "CPU times: user 1min 5s, sys: 242 ms, total: 1min 5s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(gbc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(gbc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Random Forest\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.9987\n",
      "score on train: 0.9992666666666666\n",
      "CPU times: user 13.5 s, sys: 172 ms, total: 13.7 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators = number of desission trees\n",
    "rf = RandomForestClassifier(n_estimators=30,max_depth=9)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(rf.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(rf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Voting Classifier\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.9967\n",
      "score on train: 0.99975\n",
      "CPU times: user 2min 58s, sys: 2.45 s, total: 3min\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 1) naive bias = mnb\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "# 2) logistic regression =lr\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "# 3) random forest =rf\n",
    "rf = RandomForestClassifier(n_estimators=30,max_depth=9)\n",
    "# 4) suport vecotr mnachine = svm\n",
    "svm=LinearSVC(C=0.0001)\n",
    "\n",
    "evc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm)])\n",
    "evc.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(evc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(evc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.00) [Naive Bayes]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00 (+/- 0.00) [Logistic Regression]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([mnb, lr, rf, svm, evc], ['Naive Bayes', 'Logistic Regression', 'Random Forest', 'Support Vector Machine','Ensemble']):\n",
    "    scores = cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Deep Learning \n",
    "\n",
    "Keras Documentation:\n",
    "* Sequential Model: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "50000/50000 [==============================] - 0s 8us/step - loss: 0.6133 - accuracy: 0.9759 - val_loss: 0.0458 - val_accuracy: 0.9932\n",
      "Epoch 2/4\n",
      "50000/50000 [==============================] - 0s 5us/step - loss: 0.0280 - accuracy: 0.9961 - val_loss: 0.0308 - val_accuracy: 0.9967\n",
      "Epoch 3/4\n",
      "50000/50000 [==============================] - 0s 5us/step - loss: 0.0183 - accuracy: 0.9974 - val_loss: 0.0269 - val_accuracy: 0.9965\n",
      "Epoch 4/4\n",
      "50000/50000 [==============================] - 0s 5us/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.0266 - val_accuracy: 0.9979\n",
      "\n",
      "train shape: (60000, 784)\n",
      "10000/10000 [==============================] - 0s 12us/step\n",
      "score on test: 0.998199999332428\n",
      "60000/60000 [==============================] - 1s 10us/step\n",
      "score on train: 0.9987833499908447\n",
      "CPU times: user 3.15 s, sys: 452 ms, total: 3.6 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "# split an additional validation dataset\n",
    "x_validation=x_train[:10000]\n",
    "x_partial_train=x_train[10000:]\n",
    "y_validation=y_train[:10000]\n",
    "y_partial_train=y_train[10000:]\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(784,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 1.3866 - accuracy: 0.7538 - val_loss: 0.5433 - val_accuracy: 0.9557\n",
      "Epoch 2/4\n",
      "50000/50000 [==============================] - 0s 5us/step - loss: 0.6093 - accuracy: 0.8162 - val_loss: 0.4227 - val_accuracy: 0.9860\n",
      "Epoch 3/4\n",
      "50000/50000 [==============================] - 0s 5us/step - loss: 0.5213 - accuracy: 0.8350 - val_loss: 0.3398 - val_accuracy: 0.9909\n",
      "Epoch 4/4\n",
      "50000/50000 [==============================] - 0s 6us/step - loss: 0.4648 - accuracy: 0.8442 - val_loss: 0.2574 - val_accuracy: 0.9919\n",
      "\n",
      "train shape: (60000, 784)\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "score on test: 0.9918000102043152\n",
      "60000/60000 [==============================] - 1s 14us/step\n",
      "score on train: 0.9917666912078857\n",
      "CPU times: user 3.91 s, sys: 540 ms, total: 4.45 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "\n",
    "# add validation dataset\n",
    "validation_split=10000\n",
    "x_validation=x_train[:validation_split]\n",
    "x_partial_train=x_train[validation_split:]\n",
    "y_validation=y_train[:validation_split]\n",
    "y_partial_train=y_train[validation_split:]\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(784,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
