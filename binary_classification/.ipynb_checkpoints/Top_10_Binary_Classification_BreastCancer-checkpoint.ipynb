{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Algorithms for Binary Classification [Beginner's Guide]\n",
    "\n",
    "#### How to implement the 10 most important binary classification algorithms with a few lines of Python and how they perform\n",
    "\n",
    "\n",
    "1. Naive Bayes\n",
    "2. Logistic Regression\n",
    "3. K-Nearest Neighbours\n",
    "4. Support Vector Machine\n",
    "5. Decision Tree \n",
    "6. Bagging  Decision Tree (Ensemble Learning I)\n",
    "7. Boosted Decision Tree (Ensemble Learning II)\n",
    "8. Random Forest (Ensemble Learning III)\n",
    "9. Voting Classification (Ensemble Learning IV)\n",
    "10. Deep Learning with a neuronal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.datasets as keras_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "The wisconsin breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "It is included in the Sklearn Module\n",
    "\n",
    "Data Source: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Load data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x, y = load_breast_cancer(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Check out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(143, 30)\n",
      "(426,)\n",
      "(143,)\n",
      "[1.206e+01 1.890e+01 7.666e+01 4.453e+02 8.386e-02 5.794e-02 7.510e-03\n",
      " 8.488e-03 1.555e-01 6.048e-02 2.430e-01 1.152e+00 1.559e+00 1.802e+01\n",
      " 7.180e-03 1.096e-02 5.832e-03 5.495e-03 1.982e-02 2.754e-03 1.364e+01\n",
      " 2.706e+01 8.654e+01 5.626e+02 1.289e-01 1.352e-01 4.506e-02 5.093e-02\n",
      " 2.880e-01 8.083e-02]\n"
     ]
    }
   ],
   "source": [
    "# check otu a sample\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "(25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train and test data\n",
    "x_train=vectorize_sequence(imdb_train_data,10000)\n",
    "x_test=vectorize_sequence(imdb_test_data,10000)\n",
    "\n",
    "# convert train and test labels into float numpy vector\n",
    "y_train=np.asarray(imdb_train_labels).astype('float32')\n",
    "y_test=np.asarray(imdb_test_labels).astype('float32')\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n",
    "Sklearn Documentation: \n",
    "* Naive Bayes: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "* MultinomialNB: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.9020979020979021\n",
      "score on train: 0.8943661971830986\n",
      "CPU times: user 2.97 ms, sys: 1.32 ms, total: 4.29 ms\n",
      "Wall time: 3.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(mnb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression\n",
    "\n",
    "Sklearn Documentation: \n",
    "* LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* SGD Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.951048951048951\n",
      "score on train: 0.960093896713615\n",
      "CPU times: user 1.38 s, sys: 38.3 ms, total: 1.42 s\n",
      "Wall time: 352 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(max_iter=5000)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(lr.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.7412587412587412\n",
      "score on train: 0.7582159624413145\n",
      "CPU times: user 4.1 ms, sys: 1.24 ms, total: 5.34 ms\n",
      "Wall time: 3.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logistic regression with stochastic gradient decent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(sgd.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(sgd.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-Nearest Neighbours\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.9370629370629371\n",
      "score on train: 0.9413145539906104\n",
      "CPU times: user 1.51 s, sys: 264 ms, total: 1.77 s\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5,algorithm = 'ball_tree')\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine\n",
    "\n",
    "Sklearn Documentation:\n",
    "* SVM Overview: https://scikit-learn.org/stable/modules/svm.html\n",
    "* LinearSVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.9370629370629371\n",
      "score on train: 0.9225352112676056\n",
      "CPU times: user 28.8 ms, sys: 2.53 ms, total: 31.4 ms\n",
      "Wall time: 30.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm=LinearSVC(C=0.0001)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(svm.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(svm.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.9300699300699301\n",
      "score on train: 0.971830985915493\n",
      "CPU times: user 7.11 ms, sys: 1.92 ms, total: 9.03 ms\n",
      "Wall time: 7.43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=10,max_depth=3)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \"  + str(clf.score(x_test, y_test)))\n",
    "print(\"score on train: \" + str(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bagging Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* overview ensemble methods: https://scikit-learn.org/stable/modules/ensemble.html\n",
    "* bagging classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.9440559440559441\n",
      "score on train: 0.9671361502347418\n",
      "CPU times: user 30.5 ms, sys: 2.19 ms, total: 32.7 ms\n",
      "Wall time: 31.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=3),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(bg.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Boosting Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* AdaBoost Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "* Gradien Boosting Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.958041958041958\n",
      "score on train: 1.0\n",
      "CPU times: user 356 ms, sys: 3.42 ms, total: 360 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),n_estimators=100,learning_rate=0.5)\n",
    "adb.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(adb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (426, 30)\n",
      "score on test: 0.972027972027972\n",
      "score on train: 1.0\n",
      "CPU times: user 398 ms, sys: 4 ms, total: 402 ms\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(gbc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(gbc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Random Forest\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.958041958041958\n",
      "score on train: 0.9765258215962441\n",
      "CPU times: user 384 ms, sys: 3.79 ms, total: 387 ms\n",
      "Wall time: 386 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators = number of desission trees\n",
    "rf = RandomForestClassifier(n_estimators=300,max_depth=3)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(rf.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(rf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Voting Classifier\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.965034965034965\n",
      "score on train: 0.9694835680751174\n",
      "CPU times: user 1.89 s, sys: 43.1 ms, total: 1.93 s\n",
      "Wall time: 483 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 1) naive bias = mnb\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "# 2) logistic regression =lr\n",
    "lr=LogisticRegression(max_iter=5000)\n",
    "# 3) random forest =rf\n",
    "rf = RandomForestClassifier(n_estimators=30,max_depth=3)\n",
    "# 4) suport vecotr mnachine = svm\n",
    "svm=LinearSVC(max_iter=5000)\n",
    "\n",
    "evc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm)])\n",
    "evc.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(evc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(evc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89 (+/- 0.02) [Naive Bayes]\n",
      "Accuracy: 0.96 (+/- 0.03) [Logistic Regression]\n",
      "Accuracy: 0.95 (+/- 0.01) [Random Forest]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.13) [Support Vector Machine]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.03) [Ensemble]\n",
      "CPU times: user 16.2 s, sys: 237 ms, total: 16.4 s\n",
      "Wall time: 4.35 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aortner/anaconda3/envs/Python3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([mnb, lr, rf, svm, evc], ['Naive Bayes', 'Logistic Regression', 'Random Forest', 'Support Vector Machine','Ensemble']):\n",
    "    scores = cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Deep Learning \n",
    "\n",
    "Keras Documentation:\n",
    "* Sequential Model: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 100 samples\n",
      "Epoch 1/4\n",
      "326/326 [==============================] - 0s 446us/step - loss: 47.5639 - accuracy: 0.3804 - val_loss: 39.9701 - val_accuracy: 0.3500\n",
      "Epoch 2/4\n",
      "326/326 [==============================] - 0s 10us/step - loss: 39.5415 - accuracy: 0.3804 - val_loss: 33.9176 - val_accuracy: 0.3500\n",
      "Epoch 3/4\n",
      "326/326 [==============================] - 0s 9us/step - loss: 33.5548 - accuracy: 0.3804 - val_loss: 28.8001 - val_accuracy: 0.3500\n",
      "Epoch 4/4\n",
      "326/326 [==============================] - 0s 10us/step - loss: 28.4890 - accuracy: 0.3804 - val_loss: 24.3378 - val_accuracy: 0.3500\n",
      "\n",
      "train shape: (426, 30)\n",
      "143/143 [==============================] - 0s 34us/step\n",
      "score on test: 0.37062937021255493\n",
      "426/426 [==============================] - 0s 22us/step\n",
      "score on train: 0.3732394278049469\n",
      "CPU times: user 519 ms, sys: 21 ms, total: 540 ms\n",
      "Wall time: 517 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "# split an additional validation dataset\n",
    "x_validation=x_train[:100]\n",
    "x_partial_train=x_train[100:]\n",
    "y_validation=y_train[:100]\n",
    "y_partial_train=y_train[100:]\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(30,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 326 samples, validate on 100 samples\n",
      "Epoch 1/4\n",
      "326/326 [==============================] - 0s 656us/step - loss: 281.2553 - accuracy: 0.4172 - val_loss: 134.6446 - val_accuracy: 0.6500\n",
      "Epoch 2/4\n",
      "326/326 [==============================] - 0s 13us/step - loss: 152.0283 - accuracy: 0.6043 - val_loss: 132.6610 - val_accuracy: 0.6500\n",
      "Epoch 3/4\n",
      "326/326 [==============================] - 0s 10us/step - loss: 144.9809 - accuracy: 0.6196 - val_loss: 130.2623 - val_accuracy: 0.6500\n",
      "Epoch 4/4\n",
      "326/326 [==============================] - 0s 12us/step - loss: 138.0184 - accuracy: 0.5982 - val_loss: 128.5899 - val_accuracy: 0.6500\n",
      "\n",
      "train shape: (426, 30)\n",
      "143/143 [==============================] - 0s 34us/step\n",
      "score on test: 0.6293706297874451\n",
      "426/426 [==============================] - 0s 23us/step\n",
      "score on train: 0.6267605423927307\n",
      "CPU times: user 697 ms, sys: 23.9 ms, total: 721 ms\n",
      "Wall time: 693 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "\n",
    "# add validation dataset\n",
    "validation_split=100\n",
    "x_validation=x_train[:validation_split]\n",
    "x_partial_train=x_train[validation_split:]\n",
    "y_validation=y_train[:validation_split]\n",
    "y_partial_train=y_train[validation_split:]\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(4,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(30,)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(4,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
