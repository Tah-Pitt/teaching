{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Algorithms for Binary Classification [Beginner's Guide]\n",
    "\n",
    "#### How to implement the 10 most important binary classification algorithms with a few lines of Python and how they perform\n",
    "\n",
    "\n",
    "1. Naive Bayes\n",
    "2. Logistic Regression\n",
    "3. K-Nearest Neighbours\n",
    "4. Support Vector Machine\n",
    "5. Decision Tree \n",
    "6. Bagging  Decision Tree (Ensemble Learning I)\n",
    "7. Boosted Decision Tree (Ensemble Learning II)\n",
    "8. Random Forest (Ensemble Learning III)\n",
    "9. Voting Classification (Ensemble Learning IV)\n",
    "10. Deep Learning with a neuronal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.datasets as keras_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "IMDB Ratings for binary Sentiment Analysis with Natural Language Processing.\n",
    "\n",
    "Data Source: https://keras.io/api/datasets/imdb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Load data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from keras.dataset and directly split the tuples into seperated variables\n",
    "\n",
    "(imdb_train_data,imdb_train_labels),(imdb_test_data,imdb_test_labels)=keras_data.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Check out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "[1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# check otu a sample\n",
    "print(imdb_train_data.shape)\n",
    "print(imdb_test_data.shape)\n",
    "print(imdb_train_labels.shape)\n",
    "print(imdb_test_labels.shape)\n",
    "\n",
    "print(imdb_train_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map tokenized vector back to text\n",
    "\n",
    "word_index = keras_data.imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "decoded_word_index = ''.join([reverse_word_index.get(i-3,'?') for i in imdb_train_data[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?beginsbetterthanitendsfunnythattherussiansubmarinecrew?allotheractorsit'slikethosesceneswheredocumentaryshotsbrbrspoilerpartthemessage?wascontrarytothewholestoryitjustdoesnot?brbr\n",
      " \n",
      "1: the\n",
      "2: and\n",
      "3: a\n",
      "4: of\n",
      "5: to\n",
      "6: is\n",
      "7: br\n",
      "8: in\n",
      "9: it\n",
      "10: i\n"
     ]
    }
   ],
   "source": [
    "# show decoded sample\n",
    "print(decoded_word_index)\n",
    "print(' ')\n",
    "\n",
    "# show word index list\n",
    "for key in sorted(reverse_word_index.keys()):\n",
    "    if(key<=10): \n",
    "        print(\"%s: %s\" % (key, reverse_word_index[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Vectorize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sequences,dimensions):\n",
    "    results=np.zeros((len(sequences),dimensions))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "(25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train and test data\n",
    "x_train=vectorize_sequence(imdb_train_data,10000)\n",
    "x_test=vectorize_sequence(imdb_test_data,10000)\n",
    "\n",
    "# convert train and test labels into float numpy vector\n",
    "y_train=np.asarray(imdb_train_labels).astype('float32')\n",
    "y_test=np.asarray(imdb_test_labels).astype('float32')\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n",
    "Sklearn Documentation: \n",
    "* Naive Bayes: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "* MultinomialNB: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.83936\n",
      "score on train: 0.86884\n",
      "CPU times: user 2.99 s, sys: 14.7 ms, total: 3.01 s\n",
      "Wall time: 989 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(mnb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression\n",
    "\n",
    "Sklearn Documentation: \n",
    "* LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* SGD Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.86204\n",
      "score on train: 0.98984\n",
      "CPU times: user 5min 8s, sys: 19.6 s, total: 5min 28s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(lr.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.84936\n",
      "score on train: 0.98904\n",
      "CPU times: user 22.8 s, sys: 86 ms, total: 22.9 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logistic regression with stochastic gradient decent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(sgd.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(sgd.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-Nearest Neighbours\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.62468\n",
      "score on train: 0.7854\n",
      "CPU times: user 1h 21min 56s, sys: 33.7 s, total: 1h 22min 30s\n",
      "Wall time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5,algorithm = 'ball_tree')\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine\n",
    "\n",
    "Sklearn Documentation:\n",
    "* SVM Overview: https://scikit-learn.org/stable/modules/svm.html\n",
    "* LinearSVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.8514\n",
      "score on train: 0.86272\n",
      "CPU times: user 2.7 s, sys: 28.9 ms, total: 2.73 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm=LinearSVC(C=0.0001)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(svm.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(svm.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.70496\n",
      "score on train: 1.0\n",
      "CPU times: user 3min 54s, sys: 2.48 s, total: 3min 56s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \"  + str(clf.score(x_test, y_test)))\n",
    "print(\"score on train: \" + str(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bagging Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* overview ensemble methods: https://scikit-learn.org/stable/modules/ensemble.html\n",
    "* bagging classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.77592\n",
      "score on train: 0.93372\n",
      "CPU times: user 8min 2s, sys: 43.4 s, total: 8min 45s\n",
      "Wall time: 8min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(bg.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Boosting Decision Tree\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "* AdaBoost Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "* Gradien Boosting Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.78664\n",
      "score on train: 0.80232\n",
      "CPU times: user 5min 12s, sys: 14.8 s, total: 5min 27s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "adb.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(adb.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 10000)\n",
      "score on test: 0.70112\n",
      "score on train: 0.69992\n",
      "CPU times: user 3min 25s, sys: 2.54 s, total: 3min 27s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(gbc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(gbc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Random Forest\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.80336\n",
      "score on train: 0.83244\n",
      "CPU times: user 14.6 s, sys: 1.06 s, total: 15.6 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators = number of desission trees\n",
    "rf = RandomForestClassifier(n_estimators=30,max_depth=9)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(rf.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(rf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Voting Classifier\n",
    "\n",
    "Sklearn Documentation:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.86316\n",
      "score on train: 0.91172\n",
      "CPU times: user 5min 35s, sys: 19.2 s, total: 5min 54s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 1) naive bias = mnb\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "# 2) logistic regression =lr\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "# 3) random forest =rf\n",
    "rf = RandomForestClassifier(n_estimators=30,max_depth=9)\n",
    "# 4) suport vecotr mnachine = svm\n",
    "svm=LinearSVC(C=0.0001)\n",
    "\n",
    "evc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm)])\n",
    "evc.fit(x_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(evc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(evc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.01) [Naive Bayes]\n",
      "Accuracy: 0.87 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.80 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.85 (+/- 0.00) [Support Vector Machine]\n",
      "Accuracy: 0.87 (+/- 0.00) [Ensemble]\n",
      "CPU times: user 44min 2s, sys: 3min 35s, total: 47min 38s\n",
      "Wall time: 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([mnb, lr, rf, svm, evc], ['Naive Bayes', 'Logistic Regression', 'Random Forest', 'Support Vector Machine','Ensemble']):\n",
    "    scores = cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Deep Learning \n",
    "\n",
    "Keras Documentation:\n",
    "* Sequential Model: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "24000/24000 [==============================] - 1s 61us/step - loss: 0.4519 - accuracy: 0.8171 - val_loss: 0.3179 - val_accuracy: 0.8840\n",
      "Epoch 2/4\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.2595 - accuracy: 0.9108 - val_loss: 0.2716 - val_accuracy: 0.8880\n",
      "Epoch 3/4\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.2015 - accuracy: 0.9286 - val_loss: 0.2603 - val_accuracy: 0.8910\n",
      "Epoch 4/4\n",
      "24000/24000 [==============================] - 1s 55us/step - loss: 0.1686 - accuracy: 0.9410 - val_loss: 0.2697 - val_accuracy: 0.8850\n",
      "\n",
      "train shape: (25000, 10000)\n",
      "25000/25000 [==============================] - 1s 40us/step\n",
      "score on test: 0.8771600127220154\n",
      "25000/25000 [==============================] - 1s 40us/step\n",
      "score on train: 0.9545199871063232\n",
      "CPU times: user 12 s, sys: 2.86 s, total: 14.9 s\n",
      "Wall time: 7.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "# split an additional validation dataset\n",
    "x_validation=x_train[:1000]\n",
    "x_partial_train=x_train[1000:]\n",
    "y_validation=y_train[:1000]\n",
    "y_partial_train=y_train[1000:]\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.6984 - accuracy: 0.6125 - val_loss: 0.6296 - val_accuracy: 0.7830\n",
      "Epoch 2/4\n",
      "24000/24000 [==============================] - 1s 49us/step - loss: 0.6366 - accuracy: 0.7048 - val_loss: 0.5750 - val_accuracy: 0.8570\n",
      "Epoch 3/4\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.5965 - accuracy: 0.7494 - val_loss: 0.5226 - val_accuracy: 0.8600\n",
      "Epoch 4/4\n",
      "24000/24000 [==============================] - 1s 49us/step - loss: 0.5656 - accuracy: 0.7800 - val_loss: 0.4917 - val_accuracy: 0.8700\n",
      "\n",
      "train shape: (25000, 10000)\n",
      "25000/25000 [==============================] - 1s 42us/step\n",
      "score on test: 0.8784400224685669\n",
      "25000/25000 [==============================] - 1s 42us/step\n",
      "score on train: 0.9075599908828735\n",
      "CPU times: user 12.1 s, sys: 1.78 s, total: 13.9 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "\n",
    "# add validation dataset\n",
    "validation_split=1000\n",
    "x_validation=x_train[:validation_split]\n",
    "x_partial_train=x_train[validation_split:]\n",
    "y_validation=y_train[:validation_split]\n",
    "y_partial_train=y_train[validation_split:]\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "\n",
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
